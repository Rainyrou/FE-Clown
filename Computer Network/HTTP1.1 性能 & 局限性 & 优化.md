##### 性能

HTTP 协议基于 TCP/IP，且使用了请求 -应答的通信模式

1. 长连接

HTTP/1.0 性能上的一大缺陷是，每发起一个请求，都要新建一次 TCP 连接(三次握手)，而且是串行请求。这做了无谓的 TCP 连接建立与断开，增加了通信开销

为解决上述问题，HTTP/1.1 提出长连接的通信方式，也叫持久连接。这减少了 TCP 连接的重复建立与断开所造成的额外开销，减轻了服务器的负载

长连接的特点是：只要任意一端没有明确提出断开连接，则保持 TCP 连接状态

2. 管道网络传输

HTTP/1.1 采用长连接的方式，这使得 pipeline 网络传输成为可能。即在同一个 TCP 连接里，客户端可以同时发起多个请求，第一个请求发出后，不必等待其返回，就可以发起第二个请求，从而减少整体的响应时间

但服务器还是按照顺序，先回应 A 请求，处理完后再回应 B 请求。要是前面的回应非常慢，后面就会有大量请求排队等待，即队头阻塞

3. 队头阻塞

请求 - 应答模式加剧了 HTTP 的性能问题。因为按照顺序的请求序列中的某一请求被阻塞时，在后面排队的所有请求也一同被阻塞了，导致客户端一直请求不到数据，好比上班路上塞车

##### 局限性

1. 请求/响应 Header 未经压缩就发送，头部信息越多延迟越大，只能压缩 Body 部分，每次重复发送相同的头部造成大量开销浪费

- 含很多固定的字段，比如 Cookie、User Agent、Accept 等，这些字段加起来高达几百甚至上千字节
- 请求和响应报文有大量字段值都是重复的，占用大量带宽
- 字段是 ASCII 编码的，易于观察，但效率低

2. 服务器按请求顺序依次响应，如果服务器响应慢，导致客户端一直请求不到数据，即队头阻塞问题
3. 没有请求优先级控制
4. 只能从客户端发起请求，服务器被动响应

##### 优化

![[Pasted image 20231109115046.png]]

###### 1. 使用 KeepAlive 将 HTTP/1.1 从短连接变成长链接

它从底层的传输层入手，通过减少 TCP 连接建立和断开的次数，来减少网络传输的延迟

###### 2. 尽量避免发送 HTTP 请求

将重复的 HTTP 请求缓存到本地。HTTP 头部有不少针对缓存的字段。客户端会把第一次请求及响应的数据保存在本地磁盘上，其中将请求的 URL 作为 key，而响应作为 value，两者形成映射关系

这样当后续发起相同请求时，就可以先在本地磁盘上通过 key 查找对应的 value，即响应，如果找到，就直接从本地获取

服务器在发送 HTTP 响应时，会估算一个过期时间，并把该信息放到响应头中，这样客户端在查看响应头的信息时，一旦发现缓存的响应过期，就会重新发送网络请求

客户端在重新发送请求时，会在请求的 Etag 头部带上第一次请求时响应头中的摘要，这个摘要是唯一标识响应的资源，当服务器收到请求后，会将本地资源的摘要与请求中的摘要进行比较。如果不同，服务器在响应时会带上新的资源。如果相同，服务器仅返回 304 状态码，告诉客户端缓存仍有效

###### 3. 减少请求次数

- 减少重定向请求次数

服务器上的资源由于迁移、维护等原因从 url1 移至 ur2 后，而客户端不知情，它继续请求 ur1，这时服务器返回 302 响应码和 Location 头部字段，告诉客户端该资源已迁移至 url2 了，于是客户端请求 url2

服务端往往不只一台服务器，比如源服务器的上一级是代理服务器，然后代理服务器才与客户端通信，重定向会导致客户端与代理服务器之间 2 次消息传递

因此，重定向的工作交由代理服务器完成，可减少 HTTP 请求次数，且让代理服务器知晓重定向规则，进一步减少消息传递次数

![[Pasted image 20231109122931.png]]

其中 301 和 308 响应码告诉客户端可以将重定向响应缓存到本地磁盘，之后客户端就会自动用 url2 替代 url1 访问服务器资源

2. 合并请求

- 将多个访问小文件的请求合并成一个大的请求，减少 HTTP 请求次数和 TCP 连接次数
- 使用 CSS Image Sprites 将多个小图片合并成大图片
- 使用 Webpack 等打包工具将 JS 和 CSS 等资源合并打包成大文件
- 将图片的二进制数据用 base64 编码，以 URL 的形式嵌入到 HTML 文件

但也有了新的问题，当大文件的某一资源发生变更后，客户端必须重新下载完整的大文件，这带来了额外的网络开销

3. 延迟发送请求

按需获取，分页查询，只获取当前用户所看到的页面资源，当用户下滑页面时，再从服务器拉取资源

###### 4. 减少 HTTP 响应数据的大小

无损压缩：资源经过压缩后，信息不被破坏，还能恢复原样，适合于文本文件、可执行文件和源代码

1. 压缩代码的语法规则，去掉多余的空格和换行符等
2. 建立原始数据的统计模型，哈夫曼编码算法，用较短的二进制比特序列表示常用数据，用较长的二进制比特序列表示罕见数据
3. gzip。在 HTTP 请求中，客户端通过头部 Accept-Encoding 字段告诉服务器，它所支持的压缩算法。服务器通过响应头部 Content-Encoding 字段告诉客户端返回资源所使用的压缩算法

- 有损压缩

图片压缩，使用 WebP 格式
音频压缩，使用增量数据
