###### 图片转 Base64

作为跨平台通用的传输格式，将图片转换为 Base64 编码格式可直接嵌入 JSON 格式请求，以字符串形式直接内嵌于 HTML 或 CSS 文件中以减少 HTTP 请求数，但 Base64 编码使数据膨胀约 33%（每 3 字节需 4 个字符编码），不适用于大文件上传，解码 Base64 字符串损耗额外时间且浏览器无法独立缓存直接嵌入的 Base64 图片，刷新页面时需重新加载完整数据

Base64 为一种将二进制数据编码为 ASCII 字符串的方式，其使用 64 个 ASCII 字符（A-Z, a-z, 0-9, `+`, `/`）和填充字符 `=`

1. 将输入数据按 3 个字节一组进行分段
2. 将这 24 位分成 4 组，每组 6 位，取值范围为 0-63，对应一个 Base64 字符
3. 若数据字节数不是 3 的倍数则最后一组用 `=` 号填充使输出的字符总数为 4 的倍数以保持数据完整性如字母 A 的 ASCII 二进制编码为 01000001，将其转换为 Base64 按 3 字节分段，填充到 4 个字符如 QQ==

其他格式：

1. 通过 `FormData` 对象上传二进制文件 Blob

```js
const formData = new FormData();
formData.append("file", file);
fetch("/upload", { method: "POST", body: formData });
```

2. 上传本地文件或可访问的网络资源之 URL 路径，本地缓存
3. 若图片存储于服务端，通过 API 只返回图片 URL 路径，按需加载

###### 分片上传

分片上传：将一个大文件分为若干块，一块一块传输，减少重新上传的性能开销如大文件上传时间较久，加之网络不稳定等因素容易导致上传中断，可采用分片上传来解决这一问题，只需重传剩余分片即可，而不是重传整个文件

![de321c2893b6864beffb05193fa81c68.png](https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/276bab12fc544dbab9b6c26fc2ebb5b6~tplv-k3u1fbpfcp-jj-mark:3024:0:0:0:q75.awebp#?w=734&h=596&s=84897&e=png&b=ffffff)

选择合适分片：

1. 分片过小导致上传的 HTTP 请求过多，但分片过大，网络中断时重传开销较大
2. 服务端有固定大小的接收 Buffer，分片大小为该值的整数倍如 5/10MB
3. 分片大小决定并行上传效率，分片过大，并行上传灵活度降低

判断文件大小，若文件还没有一个分片大则直接走单文件上传逻辑，否则走分片上传逻辑，与后端约定的分片大小为 5MB

MD5：一种加密哈希算法，MD5 将输入数据分割为固定大小数据块，通过预设的初始向量初始化参数，反复加密各个数据块，迭代压缩，逐步生成最终散列值（一个 128 位的哈希值，以 32 位的十六进制字符串表示），无论文件内容大小/结构如何，若其内容一致，则 MD5 值相同

1. 在大文件上传开始前通过 `SparkMD5.ArrayBuffer` 将整个文件读取为二进制数据并进行 Hash 计算，这样得到的 MD5 值在客户端和服务端间保持一致，不会因网络传输而改变，生成的文件唯一标识符用于判断文件是否已上传过 + 文件校验以确保上传完后的文件与源文件一致 + 断点续传时查找服务端保存的记录以确认哪些分片已上传
2. 各个分片在其上传时分别计算 MD5 值以便后端接收到各个分片后逐个验证其 MD5 值以保证其完整性
3. 整体和分片 MD5 的结合既保证文件的完整性且支持分片的灵活校验

计算数据散列值：

1. MD5 将数据长度填充到 512 位的整数倍
2. 初始化 4 个 32 位缓存变量以存储中间和最终之散列值
3. 对每一组 512 位的数据块执行 4 轮共 64 次的操作，每轮操作中涉及不同的非线性函数和位操作
4. 所有块处理完后，将 4 个缓存值合并，输出最终的 128 位散列值

截取解析误判：

1. 尽管 MD5 碰撞概率较低，但仍可能存在不同文件或相同文件的不同版本产生相同之 MD5 值的情况
2. 文件元数据或特定格式的头部信息在不同文件间相同但实际内容不同，仅计算文件的前 N 字节部分含相同元数据

解决方案：

1. 考虑更强的哈希算法如 SHA-256 或 SHA-512
2. 存储更多元数据以综合比较

状态码：

206 Partial Content：请求成功，返回的响应体数据不是全部资源如文件上传时前端按特定范围上传分片或文件下载时前端请求特定范围数据，响应头部字段 `Content-Range` 指定返回内容范围
416 Range Not Satisfiable：请求范围不满足，前端请求范围超过后端可提供的内容范围

在大文件上传开始前通过 `SparkMD5.ArrayBuffer` 将整个文件读取为二进制数据并进行 Hash 计算，各个分片在其上传时分别计算 MD5 值，字节流 blob 格式 Blob.prototype.slice 切片，在首个分片里携带完整文件的 MD5 值和文件分片数，后端判断该文件是否已上传过，大文件上传方式为并行上传，用 `promise.allSettled` 控制，在上传每一片时携带该片为第几片的 index 参数，全部分片上传完后调用查询接口，后端返回哪些分片未接收到的信息，若未接收到部分分片则走续传，重传上次传输失败的分片，再次请求查询接口，执行上述步骤

文件上传时网络中断：通过 localStorage 记录切片上传信息或每次在上传切片前向后端查询该切片是否已上传
暂停上传：请求接口中断上传即中断 promise.allSettled 的外层循环
某分片上传失败：promise.allSettled 的失败数组里有存储数据
判断某分片上传失败：promise 报错即失败且后端通知哪些分片上传失败
多分片同时上传一部分：promise.allSettled 接收一个 promise 数组，并行执行里面的 promise，返回一个结果数组，里面的每一项正好对应 promise 数组里每一项 promise 的结果

量化大文件上传传输时间和内存开销：

1. 传输时间：从大文件开始上传到上传完成所需时间

```js
const startTime = Date.now();
uploadFile(file).then(() => {
  const endTime = Date.now();
  const uploadTime = endTime - startTime;
  console.log(`上传时间：${uploadTime} ms`);
});
```

2. 带宽情况：网络在单位时间内传输的数据量以 Mbps 表示

```js
const fileSizeInBytes = file.size;
const uploadTimeInSeconds = uploadTime / 1000;
const uploadSpeedMbps = (fileSizeInBytes * 8) / (uploadTimeInSeconds * 1024 * 1024);
```

3. 内存开销

```js
const initialMemoryUsage = performance.memory.usedJSHeapSize;
uploadFile(file).then(() => {
  const finalMemoryUsage = performance.memory.usedJSHeapSize;
  const memoryUsage = finalMemoryUsage - initialMemoryUsage;
  console.log(`内存开销：${memoryUsage} bytes`);
});
```

后端处理分片上传：

1. 接收分片请求：各个分片上传请求包括完整文件 MD5 值，分片序号 index，分片大小及分片 MD5 值，若为文件的首次上传，后端在数据库为其创建唯一存储记录，标记文件上传状态和分片列表
2. 校验分片：后端接收分片后计算收到的分片 MD5 值并与前端发送的 MD5 值比对，若一致则分片数据完整未损坏，否则返回错误信息给前端，要求重传该分片，此外后端根据文件 MD5 值和分片序号 index 判断分片是否已接收以免重复存储
3. 分片存储：后端通过文件或分布式存储系统将分片数据保存到临时存储位置，根据完整文件 MD5 值和分片序号 index 命名分片文件
4. 分片合并：后端接收到所有分片的上传请求且根据分片的 index 检查所有分片齐全后，实时校验，依次读取每个分片的数据流按序流式将数据写入最终文件中，避免一次性加载到内存，若合并失败则自动重试合并，若合并多次失败则后端将错误信息返回给前端，提示用户重新上传，合并失败时后端保留已上传的分片，以便用户重新发起合并请求，减少数据损耗。合并后的文件存储于指定目录，采用与分片相同的组织结构，最终文件的命名规则包含文件 MD5 值、上传时间戳和原文件名以便于唯一标识，且后端将文件格式与相关元数据如完整文件 MD5 值、文件大小、上传时间戳和原文件名等记录于数据库以后续管理、下载和校验文件
5. 文件校验：分片合并完后，后端计算其 MD5 值并与前端发送的完整文件 MD5 比对，确保文件在上传和合并过程中完整未损坏
6. 清理临时数据：合并成功且校验通过后后端删除各个分片，释放存储空间并执行异步清理任务

分片上传至同一服务器：

1. Session ID：当大文件上传开始时，后端生成一个唯一 Session ID 并将其返回给前端，后续所有分片上传请求均携带该 Session ID 以确保其上传至同一服务器
2. Session Affinity：在负载均衡器上配置粘性会话，将同一用户的请求路由到同一服务器
3. 共享状态管理：后端所有实例通过共享数据库或 Redis 缓存存储文件元数据等，确保即使请求被转发到其他服务器实例，后端也能正确识别和处理

```js
<template>
  <div :class="showProgress == true ? 'loading' : ''">
    <!-- on-preview	点击文件列表中已上传的文件时的钩子 -->
    <!-- http-request  覆盖默认上传行为，自定义上传实现 -->
    <!-- limit	允许上传的最大数量 -->
    <!-- before-upload	上传文件前的钩子，参数为上传的文件，若返回 false 或 reject Promise 则停止上传。 -->
    <!-- accept	接受上传的文件类型 -->
    <!-- multiple	是否多选 -->
    <!-- on-change	文件状态改变时的钩子，添加文件、上传成功/失败时均调用 -->
    <!-- on-remove	文件列表移除文件时的钩子 -->
    <!-- file-list	上传的文件列表如: [{name: 'food.jpg', url: 'https://xxx.cdn.com/xxx.jpg'}] -->
    <!-- on-exceed	文件超出限制时的钩子 -->
    <!-- auto-upload	是否在选取文件后立即上传 -->
    <!-- action	上传的地址如 action="https://jsonplaceholder.typicode.com/posts/"-->
    <el-upload drag multiple :auto-upload="true" :http-request="checkedFile" :before-remove="removeFile" :limit="10"
      action="/tools/upload_chunk/" :disabled="showProgress">
      <i class="el-icon-upload"></i>
      <div class="el-upload__text">
        将文件拖到此处，或
        <em>点击上传</em>
      </div>
    </el-upload>
    <el-dialog title="正在上传" :visible.sync="showProgress" width="50%">
      <el-progress type="circle" :percentage="progress" class="progress" v-if="showProgress"></el-progress>
    </el-dialog>
  </div>
</template>
<script>
import axios from "axios";
import SparkMD5 from "spark-md5";
export default {
  data() {
    return {
      maxSize: 5 * 1024 * 1024 * 1024, // 最小单位为 b
      multiUploadSize: 100 * 1024 * 1024, // 大于此值的文件采用分块上传
      eachSize: 100 * 1024 * 1024, // 每块文件大小
      requestCancelQueue: [], // 请求方法队列，调用取消上传
      url: "/tools/upload_chunk/",
      progress: 0,
      showProgress: false,
	  eachProgress: 0, // 每上传一块的进度
      chunksKeep: 0, // 总共多少块
      fileChunksKeep: [], // 切割后的文件数组
      fileKeep: null, // 断点续传
      fileMd5Keep: "" // md5
    };
  },
  mounted() { },
  methods: {
    async checkedFile(options) {
      const {
        maxSize,
        multiUploadSize,
        getSize,
        splitUpload,
        singleUpload
      } = this;
      const { file, onProgress, onSuccess, onError } = options;
      if (file.size > maxSize) {
        return this.$message({
          message: `您选择的文件大于${getSize(maxSize)}`,
          type: "error"
        });
      }
      this.fileKeep = file;
      const uploadFunc =
        file.size > multiUploadSize ? splitUpload : singleUpload;
      try {
        await uploadFunc(file, onProgress);
        onSuccess();
      } catch (e) {
        console.error(e);
        this.$message({
          message: e.message,
          type: "error"
        });
        this.showProgress = false;
        this.progress = 0;
        onError();
      }
      const prom = new Promise((resolve, reject) => { }); /
      prom.abort = () => { };
      return prom;
    },
    getSize(size) {
      return size > 1024
        ? size / 1024 > 1024
          ? size / (1024 * 1024) > 1024
            ? (size / (1024 * 1024 * 1024)).toFixed(2) + "GB"
            : (size / (1024 * 1024)).toFixed(2) + "MB"
          : (size / 1024).toFixed(2) + "KB"
        : size.toFixed(2) + "B";
    },
    async singleUpload(file, onProgress) {
      await this.postFile(
        { file, uid: file.uid, fileName: file.fileName, chunk: 0 },
        onProgress
      );

      const reader = new FileReader();
      reader.readAsArrayBuffer(file);
      let hashMd5 = "";
      console.log(hashMd5);
      const that = this;
      function getHash(cb) {
        console.log("进入单个上传的getHash");
        reader.onload = function (e) {
          console.log("进入单个上传的getHash的函数2");
          console.log(hashMd5);
          console.log(this);
          const hash = SparkMD5.ArrayBuffer.hash(e.target.result);
          console.log(hash);
          that.hashMd5 = hash;
          console.log(that.hashMd5);
          that.fileMd5Keep = hash;
          cb(hash);
        };
      }
      await getHash(function (hash) {
        console.log(hash);
        console.log(that);
        that.validateFile({
          name: file.name,
          uid: file.uid,
          md5: hash,
          chunks: 1,
          filter_type: "user_data_file"
        });
      });
    },
    splitUpload(file, onProgress) {
      return new Promise(async (resolve, reject) => {
        try {
          const { eachSize } = this;
          const chunks = Math.ceil(file.size / eachSize);
          this.chunksKeep = chunks;
          const fileChunks = await this.splitFile(file, eachSize, chunks);
          this.fileChunksKeep = fileChunks;
          console.log("fileChunks,文件数组切割后");
          console.log(fileChunks);
          this.eachProgress = parseInt(Math.floor((100 / chunks) * 100) / 100);
          this.showProgress = true;
          let currentChunk = 0;

          for (let i = 0; i < fileChunks.length; i++) {
            console.log(currentChunk, i);
            if (Number(currentChunk) === i) {
              await this.postFile(
                {
                  chunked: true,
                  chunk: i,
                  chunks,
                  eachSize,
                  fileName: file.name,
                  fullSize: file.size,
                  uid: file.uid,
                  file: fileChunks[i]
                },
                onProgress
              );
              currentChunk++;

              this.progress += this.eachProgress;
              this.progress = this.progress > 100 ? 100 : this.progress;
            }
          }
          const spark = new SparkMD5.ArrayBuffer();
          let currentChunkMd5 = 0;
          const that = this;
          const reader = new FileReader();
          reader.onload = async function (e) {
            spark.append(e.target.result);
            currentChunkMd5++;

            if (currentChunkMd5 < chunks) {
              loadNext();
            } else {
              var hashMd5111 = spark.end();
              that.fileMd5Keep = hashMd5111;
              console.log(that);
              console.log(hashMd5111);
              await that.validateFile({
                name: file.name,
                uid: file.uid,
                md5: hashMd5111,
                chunks: fileChunks.length,
                filter_type: "git_secret_file"
              });
            }
          };

          async function loadNext() {
            const start = currentChunkMd5 * eachSize;
            const end =
              start + eachSize >= file.size ? file.size : start + eachSize;
            await reader.readAsArrayBuffer(file.slice(start, end));
          }
          this.$message({
            message: "正在进行文件加密校验",
            type: "info"
          });
          await loadNext();
          resolve();
        } catch (error) {
          reject(error);
        }
      });
    },
    againSplitUpload(file, array) {
      console.log("file,array");
      console.log(file);
      console.log(array);
      return new Promise(async (resolve, reject) => {
        try {
          const { eachSize, fileKeep } = this;
          const chunks = this.chunksKeep;
          const fileChunks = this.fileChunksKeep;
          this.showProgress = true;
          for (let i = 0; i < array.length; i++) {
            await this.postFile({
              chunked: true,
              chunk: array[i],
              chunks,
              name: file.name,
              fullSize: fileKeep.size,
              uid: file.uid,
              file: fileChunks[array[i]]
            });
            this.progress = this.progress > 100 ? 100 : this.progress;
          }

          var fileMd5KeepTwo = this.fileMd5Keep;

          const isValidate = await this.validateFile({
            chunks: fileChunks.length,
            name: file.name,
            uid: file.uid,
            md5: fileMd5KeepTwo,
            filter_type: "git_secret_file"
          });
          this.showProgress = false;
          this.progress = 0;
          resolve();
        } catch (e) {
          reject(e);
        }
      });
    },
    splitFile(file, eachSize, chunks) {
      return new Promise((resolve, reject) => {
        try {
          setTimeout(() => {
            const fileChunk = [];
            for (let chunk = 0; chunks > 0; chunks--) {
              fileChunk.push(file.slice(chunk, chunk + eachSize));
              chunk += eachSize;
            }
            resolve(fileChunk);
          }, 0);
        } catch (e) {
          console.error(e);
          reject(new Error("文件切块发生错误"));
        }
      });
    },
    removeFile(file) {
      this.requestCancelQueue[file.uid]();
      delete this.requestCancelQueue[file.uid];
      return true;
    },
    postFile(param, onProgress) {
      const formData = new FormData();
      formData.append("file", param.file);
      formData.append("uid", param.uid);
      formData.append("chunk", param.chunk);
      formData.append("filter_type", "git_secret_file");
      const { requestCancelQueue } = this;
      const config = {
        cancelToken: new axios.CancelToken(function executor(cancel) {
          if (requestCancelQueue[param.uid]) {
            requestCancelQueue[param.uid]();
            delete requestCancelQueue[param.uid];
          }
          requestCancelQueue[param.uid] = cancel;
        }),
        onUploadProgress: e => {
          if (param.chunked) {
            e.percent = Number(
              (
                ((param.chunk * (param.eachSize - 1) + e.loaded) /
                  param.fullSize) *
                100
              ).toFixed(2)
            );
          } else {
            e.percent = Number(((e.loaded / e.total) * 100).toFixed(2));
          }
          onProgress(e);
        }
      };
      return this.$http({
        url: "/tools/upload_chunk/",
        method: "POST",
        data: formData
      }).then(rs => rs.data);
    },
    validateFile(file) {
      return this.$http({
        url: "/tools/upload_chunk/upload_success/",
        method: "POST",
        data: file
      }).then(res => {
        if (res && res.status == 1) {
          this.againSplitUpload(file, res.data.error_file);
          this.$message({
            message: "有文件上传失败，正在重新上传",
            type: "warning"
          });
        } else if (res && res.status == 0) {
          this.$message({
            message: "上传成功",
            type: "success"
          });
          this.showProgress = false;
          this.progress = 0;
        } else if (res && res.status == 40008) {
          this.$message.error(res.message);
          this.showProgress = false;
          this.progress = 0;
        }
      });
    }
  }
};
</script>
<style scoped>
.loading {
  background: rgba(0, 0, 0, 0.5);
}

.progress {
  position: absolute;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  margin-top: 40px;
}

/deep/ .el-dialog {
  position: relative;
  height: 500px;
}
</style>
```
